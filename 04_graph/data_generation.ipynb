{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Graphs for Connected Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as NX\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characteristics of Leaflet Finder Graphs\n",
    "\n",
    "    count    24056.000000\n",
    "    mean         5.971566\n",
    "    std          1.305737\n",
    "    min          2.000000\n",
    "    25%          5.000000\n",
    "    50%          6.000000\n",
    "    75%          7.000000\n",
    "    max         12.000000\n",
    "    \n",
    "    \n",
    "Using NetworkX the largest graph that can be generated on a Stampede node with 32 GB memory is **10 Mio** nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#OUTPUT_DIR=os.path.join(os.getcwd(), \"data\")\n",
    "OUTPUT_DIR=\"/work/01131/tg804093/graph\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#number_of_nodes=[    10000, \n",
    "#                    100000,\n",
    "#                   1000000,\n",
    "#                  10000000,\n",
    "#                 100000000,\n",
    "#                1000000000]\n",
    "number_of_nodes=[100000000]\n",
    "\n",
    "captured_times = {}\n",
    "for number in number_of_nodes:\n",
    "    start = time.time()\n",
    "    degree_vector = np.random.normal(5.971566, 1.305737, number)\n",
    "    graph = NX.expected_degree_graph(degree_vector)\n",
    "    NX.write_edgelist(graph,\n",
    "                      os.path.join(OUTPUT_DIR, \n",
    "                        \"graph_edges_%d_%d.csv\"%(number, NX.number_of_edges(graph))),\n",
    "                      delimiter=\",\")\n",
    "    \n",
    "    end = time.time()\n",
    "    captured_times[number]=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{20000: 1.1708459854125977, 40000: 2.56634783744812, 640000: 49.59387397766113, 80000: 5.55070686340332, 1280000: 108.38637399673462, 160000: 11.38257098197937, 10000: 1.0456390380859375, 320000: 23.956480979919434}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(captured_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 124280\r\n",
      "-rw-------  1 tg804093 G-800683 65940271 Aug  1 13:41 graph_edges_1280000_3819403.csv\r\n",
      "drwx------  2 tg804093 G-800683     4096 Aug  1 13:40 .\r\n",
      "-rw-------  1 tg804093 G-800683 31826390 Aug  1 13:39 graph_edges_640000_1911152.csv\r\n",
      "-rw-------  1 tg804093 G-800683 15576940 Aug  1 13:38 graph_edges_320000_955401.csv\r\n",
      "-rw-------  1 tg804093 G-800683  7461452 Aug  1 13:38 graph_edges_160000_478000.csv\r\n",
      "-rw-------  1 tg804093 G-800683  3504310 Aug  1 13:38 graph_edges_80000_238049.csv\r\n",
      "-rw-------  1 tg804093 G-800683  1727441 Aug  1 13:37 graph_edges_40000_119599.csv\r\n",
      "-rw-------  1 tg804093 G-800683   819338 Aug  1 13:37 graph_edges_20000_58979.csv\r\n",
      "-rw-------  1 tg804093 G-800683   379940 Aug  1 13:37 graph_edges_10000_29735.csv\r\n",
      "drwx------ 12 tg804093 G-800683     4096 Aug  1 13:31 ..\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lta {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b93147bb5d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEhCAYAAABiPitQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDHJJapxBLkmNM8glqXEGuSQ17v8Dj9gz5BKpT7cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b931419ca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd = DataFrame.from_dict(captured_times, orient=\"index\")\n",
    "pd.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run ../util/init_spark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:Error while sending or receiving.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 479, in send_command\n",
      "    raise Py4JError(\"Answer from Java side is empty\")\n",
      "Py4JError: Answer from Java side is empty\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server\n",
      "Traceback (most recent call last):\n",
      "  File \"/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\", line 425, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "  File \"/home1/01131/tg804093/anaconda/lib/python2.7/socket.py\", line 228, in meth\n",
      "    return getattr(self._sock,name)(*args)\n",
      "error: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-127eca4b6dc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcount\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    982\u001b[0m         \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m         \"\"\"\n\u001b[1;32m--> 984\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36msum\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m         \u001b[1;36m6.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m         \"\"\"\n\u001b[1;32m--> 975\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mfold\u001b[1;34m(self, zeroValue, op)\u001b[0m\n\u001b[0;32m    850\u001b[0m                 \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \"\"\"\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/pyspark/traceback_utils.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, tb)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_spark_stack_depth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetCallSite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[0;32m    538\u001b[0m                 self.target_id, self.name)\n",
      "\u001b[1;32m/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry)\u001b[0m\n\u001b[0;32m    360\u001b[0m          \u001b[0mthe\u001b[0m \u001b[0mPy4J\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \"\"\"\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m         connection = GatewayConnection(self.address, self.port,\n\u001b[0;32m    324\u001b[0m                 self.auto_close, self.gateway_property)\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home1/01131/tg804093/src/supercomputing2015-tutorial/02_hadoop_on_hpc/work/spark-1.4.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;34m'server'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server"
     ]
    }
   ],
   "source": [
    "sc.parallelize([1,2,3]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
