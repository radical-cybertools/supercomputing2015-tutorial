{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans: Scitkit, Pilot and Spark/MLlib\n",
    "\n",
    "\n",
    "This is perhaps the best known database to be found in the pattern recognition literature. The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant (see <https://archive.ics.uci.edu/ml/datasets/Iris>). \n",
    "\n",
    "Source: R. A. Fisher, The Use of Multiple Measurements in Taxonomic Problems, 1936, http://rcs.chemometrics.ru/Tutorials/classification/Fisher.pdf\n",
    "\n",
    "Pictures (Source [Wikipedia](https://en.wikipedia.org/wiki/Iris_flower_data_set))\n",
    "\n",
    "<table>\n",
    "<tr><td>\n",
    "Setosa\n",
    "</td><td>\n",
    "Versicolor\n",
    "</td><td>\n",
    "Virginica\n",
    "</td></tr>\n",
    "<tr><td>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg/180px-Kosaciec_szczecinkowaty_Iris_setosa.jpg\"/> \n",
    "</td><td>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Iris_versicolor_3.jpg/320px-Iris_versicolor_3.jpg\"/>\n",
    "</td><td>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Iris_virginica.jpg/295px-Iris_virginica.jpg\"/>\n",
    "</td></tr></table>\n",
    "\n",
    "## 1. Data Overview\n",
    "\n",
    "We will begin by loading the data into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth         Name\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/pydata/pandas/master/pandas/tests/data/iris.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scikit\n",
    "\n",
    "Scikit is a machine learning library for Python built upon numpy and matplotlib. It provides functions for classification, regression, clustering and other common analytics tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "results = kmeans.fit_predict(data[['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "      <th>ClusterId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth         Name  ClusterId\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa          1\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa          1\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa          1\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa          1\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_kmeans=pd.concat([data, pd.Series(results, name=\"ClusterId\")], axis=1)\n",
    "data_kmeans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we evaluate the resulting fit (commonly referred to as the model), using the sum of squared errors and a pair plot. The following pair plot shows the scatter-plot between each of the four features. Clusters for the different species are indicated by different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of squared error: 78.9\n"
     ]
    }
   ],
   "source": [
    "print \"Sum of squared error: %.1f\"%kmeans.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data_kmeans, vars=[\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"], hue=\"ClusterId\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pilot Approach\n",
    "\n",
    "We will now use RADICAL-Pilot to compute the distance function, as a simple representation of how the above example can be executed as a task-parallel application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session id: rp.session.ip-10-144-47-195.radical.016753.0006 Pilot Manager: {'uid': 'pmgr.0000'}\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import commands\n",
    "import radical.pilot as rp\n",
    "os.environ[\"RADICAL_PILOT_DBURL\"]=\"mongodb://ec2-54-221-194-147.compute-1.amazonaws.com:24242/giannis\"\n",
    "\n",
    "def print_details(detail_object):\n",
    "    if type(detail_object)==str:\n",
    "        detail_object = ast.literal_eval(detail_object)\n",
    "    for i in detail_object:\n",
    "        detail_object[i]=str(detail_object[i])\n",
    "    #print str(detail_object)\n",
    "    return pd.DataFrame(detail_object.values(), \n",
    "             index=detail_object.keys(), \n",
    "             columns=[\"Value\"])\n",
    "\n",
    "\n",
    "session = rp.Session()\n",
    "c = rp.Context('ssh')\n",
    "c.user_id = \"radical\"\n",
    "session.add_context(c)\n",
    "pmgr = rp.PilotManager(session=session)\n",
    "umgr = rp.UnitManager (session=session,\n",
    "                       scheduler=rp.SCHED_DIRECT_SUBMISSION)\n",
    "print \"Session id: %s Pilot Manager: %s\" % (session.uid, str(pmgr.as_dict()))\n",
    "pdesc = rp.ComputePilotDescription ()\n",
    "pdesc.resource = \"local.localhost_anaconda\"\n",
    "pdesc.runtime  = 10 \n",
    "pdesc.cores    = 16\n",
    "pdesc.cleanup  = False\n",
    "pilot = pmgr.submit_pilots(pdesc)\n",
    "umgr = rp.UnitManager (session=session,\n",
    "                       scheduler=rp.SCHED_DIRECT_SUBMISSION)\n",
    "umgr.add_pilots(pilot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "In the following, we will partition the data and distribute it to a set of CUs for fast processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_clusters = 3\n",
    "clusters = data.sample(number_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLength  SepalWidth  PetalLength  PetalWidth             Name\n",
       "21           5.1         3.7          1.5         0.4      Iris-setosa\n",
       "69           5.6         2.5          3.9         1.1  Iris-versicolor\n",
       "120          6.9         3.2          5.7         2.3   Iris-virginica"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters.to_csv(\"clusters.csv\")\n",
    "data.to_csv(\"points.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Function for computing new centroids as mean of all points assigned to a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_new_centroids(distances):\n",
    "    df = pd.DataFrame(distances)\n",
    "    #print df\n",
    "    df[4] =  df[4].astype(int)\n",
    "    df = df.groupby(4)[0,1,2,3].mean()\n",
    "    centroids_np = df.as_matrix()\n",
    "    return centroids_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Mapper Function as an External Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    distances =!/opt/anaconda/bin/python mapper.py points.csv clusters.csv\n",
    "    distances_np =  np.array(eval(\" \".join(distances)))\n",
    "    new_centroids = compute_new_centroids(distances_np)\n",
    "    new_centroids_df = pd.DataFrame(new_centroids, columns=[\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"])\n",
    "    new_centroids_df.to_csv(\"clusters.csv\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Mapper Function inside RADICAL-Pilot\n",
    "\n",
    "Helper function to read output form completed compute units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urlparse\n",
    "\n",
    "def get_output(compute_unit):\n",
    "    working_directory=compute_unit.as_dict()['working_directory']\n",
    "    path = urlparse.urlparse(working_directory).path\n",
    "    output=open(os.path.join(path, \"STDOUT\")).read()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished iteration: 0\n",
      "Finished iteration: 1\n",
      "Finished iteration: 2\n",
      "Finished iteration: 3\n",
      "Finished iteration: 4\n",
      "Finished iteration: 5\n",
      "Finished iteration: 6\n",
      "Finished iteration: 7\n",
      "Finished iteration: 8\n",
      "Finished iteration: 9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    cudesc = rp.ComputeUnitDescription()\n",
    "    cudesc.executable  = \"/opt/anaconda/bin/python\"\n",
    "    cudesc.arguments   = [os.path.join(os.getcwd(), \"mapper.py\"),\n",
    "                          os.path.join(os.getcwd(), \"points.csv\"),\n",
    "                          os.path.join(os.getcwd(), \"clusters.csv\")]\n",
    "    cu_set = umgr.submit_units([cudesc])\n",
    "    umgr.wait_units()\n",
    "    output = get_output(cu_set[0])\n",
    "    distances_np =  np.array(eval(output))\n",
    "    new_centroids = compute_new_centroids(distances_np)\n",
    "    new_centroids_df = pd.DataFrame(new_centroids, columns=[\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"])\n",
    "    new_centroids_df.to_csv(\"clusters.csv\")        \n",
    "    print \"Finished iteration: %d\"%(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out final centroids computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.006000</td>\n",
       "      <td>3.418000</td>\n",
       "      <td>1.464000</td>\n",
       "      <td>0.244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.883607</td>\n",
       "      <td>2.740984</td>\n",
       "      <td>4.388525</td>\n",
       "      <td>1.434426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.853846</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>5.715385</td>\n",
       "      <td>2.053846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0     5.006000    3.418000     1.464000    0.244000\n",
       "1     5.883607    2.740984     4.388525    1.434426\n",
       "2     6.853846    3.076923     5.715385    2.053846"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_centroids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark MLLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARK Home: /usr/hdp/2.3.2.0-2950/spark-1.5.1-bin-hadoop2.6\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from math import sqrt\n",
    "\n",
    "%run ../env.py\n",
    "%run ../util/init_spark.py\n",
    "\n",
    "from pilot_hadoop import PilotComputeService as PilotSparkComputeService\n",
    "\n",
    "pilotcompute_description = {\n",
    "    \"service_url\": \"yarn-client://sc15.radical-cybertools.org\",\n",
    "    \"number_of_processes\": 5\n",
    "}\n",
    "pilot_spark = PilotSparkComputeService.create_pilot(pilotcompute_description=pilotcompute_description)\n",
    "\n",
    "sc = pilot_spark.get_spark_context()\n",
    "sqlCtx=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load and parse the data\n",
    "data_spark=sqlCtx.createDataFrame(data)\n",
    "data_spark_without_class=data_spark.select('SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert DataFrame to Tuple for MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_spark_tuple = data_spark.map(lambda a: (a[0],a[1],a[2],a[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "clusters = KMeans.train(data_spark_tuple, 3, maxIterations=10,\n",
    "                        runs=10, initializationMode=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate clustering by computing Within Set Sum of Squared Errors\n",
    "def error(point):\n",
    "    center = clusters.centers[clusters.predict(point)]\n",
    "    return sqrt(sum([x**2 for x in (point - center)]))\n",
    "\n",
    "WSSSE = data_spark_tuple.map(lambda point: error(point)).reduce(lambda x, y: x + y)\n",
    "print(\"Within Set Sum of Squared Error = \" + str(WSSSE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Pilot-Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pilot_spark.cancel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
