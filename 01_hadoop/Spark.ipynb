{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Introduction\n",
    "\n",
    "## 1. Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARK Home: /usr/hdp/2.3.2.0-2950/spark-1.5.1-bin-hadoop2.6\n",
      "SPARK HOME: /usr/hdp/2.3.2.0-2950/spark-1.5.1-bin-hadoop2.6\n",
      "PYTHONPATH: /usr/hdp/2.3.2.0-2950/spark-1.5.1-bin-hadoop2.6/python:/usr/hdp/2.3.2.0-2950/spark-1.5.1-bin-hadoop2.6/python/lib/py4j-0.8.2.1-src.zip\n"
     ]
    }
   ],
   "source": [
    "%run ../env.py\n",
    "%run ../util/init_spark.py\n",
    "\n",
    "from pilot_hadoop import PilotComputeService as PilotSparkComputeService\n",
    "\n",
    "pilotcompute_description = {\n",
    "    \"service_url\": \"yarn-client://yarn.radical-cybertools.org\",\n",
    "    \"number_of_processes\": 2\n",
    "}\n",
    "\n",
    "print \"SPARK HOME: %s\"%os.environ[\"SPARK_HOME\"]\n",
    "print \"PYTHONPATH: %s\"%os.environ[\"PYTHONPATH\"]\n",
    "\n",
    "pilot_spark = PilotSparkComputeService.create_pilot(pilotcompute_description=pilotcompute_description)\n",
    "sc = pilot_spark.get_spark_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spark: Hello RDD Abstraction\n",
    "\n",
    "Line Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1891715"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd = sc.textFile(\"/data/nasa/\")\n",
    "text_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_rdd.flatMap(lambda line: line.split(\" \")).map(lambda word: (word, 1)).reduceByKey(lambda x,y: x+y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTTP Response Code Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'403', 54),\n",
       " (u'302', 46573),\n",
       " (u'304', 132627),\n",
       " (u'500', 62),\n",
       " (u'501', 14),\n",
       " (u'200', 1701534),\n",
       " (u'404', 10845),\n",
       " (u'400', 5)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NASA\n",
    "text_rdd = sc.textFile(\"/data/nasa/\")\n",
    "text_rdd.filter(lambda x: len(x)>8).map(lambda x: (x.split()[-2],1)).reduceByKey(lambda x,y: x+y).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark-SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext, Row\n",
    "sqlContext = SQLContext(sc)\n",
    "text_filtered = text_rdd.filter(lambda x: len(x)>8)\n",
    "logs = text_filtered.top(20)\n",
    "cleaned = text_filtered.map(lambda l: (l.split(\" \")[0], l.split(\" \")[3][1:], l.split(\" \")[6], l.split(\" \")[-2]))\n",
    "rows = cleaned.map(lambda l: Row(referer=l[0], ts=l[1], response_code=l[3]))\n",
    "schemaLog = sqlContext.createDataFrame(rows)\n",
    "schemaLog.registerTempTable(\"row\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(referer=u'199.72.81.55', response_code=u'200', ts=u'01/Jul/1995:00:00:01'),\n",
       " Row(referer=u'unicomp6.unicomp.net', response_code=u'200', ts=u'01/Jul/1995:00:00:06'),\n",
       " Row(referer=u'199.120.110.21', response_code=u'200', ts=u'01/Jul/1995:00:00:09'),\n",
       " Row(referer=u'burger.letters.com', response_code=u'304', ts=u'01/Jul/1995:00:00:11'),\n",
       " Row(referer=u'199.120.110.21', response_code=u'200', ts=u'01/Jul/1995:00:00:11'),\n",
       " Row(referer=u'burger.letters.com', response_code=u'304', ts=u'01/Jul/1995:00:00:12'),\n",
       " Row(referer=u'burger.letters.com', response_code=u'200', ts=u'01/Jul/1995:00:00:12'),\n",
       " Row(referer=u'205.212.115.106', response_code=u'200', ts=u'01/Jul/1995:00:00:12'),\n",
       " Row(referer=u'd104.aa.net', response_code=u'200', ts=u'01/Jul/1995:00:00:13'),\n",
       " Row(referer=u'129.94.144.152', response_code=u'200', ts=u'01/Jul/1995:00:00:13')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(response_code=u'500', _c1=62),\n",
       " Row(response_code=u'501', _c1=14),\n",
       " Row(response_code=u'400', _c1=5),\n",
       " Row(response_code=u'403', _c1=54),\n",
       " Row(response_code=u'404', _c1=10845),\n",
       " Row(response_code=u'302', _c1=46573),\n",
       " Row(response_code=u'304', _c1=132627),\n",
       " Row(response_code=u'200', _c1=1701534)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"select response_code, count(*) from row group by response_code\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
